{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CIgT9kE4KHqe",
        "pTohUadq_HUC",
        "GeEu96leTaL6",
        "KXdYsYQmr1Aq",
        "4BipOv18sV2n",
        "1PeeinuNtAEe",
        "pdrl0p3jhcuo",
        "shwe_q3BV8Vr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [Техническое задание](https://docs.google.com/document/d/1ZIu6daXZRuDR796AHjKCku643hlM3xgYxW9E84DBJFc/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "CIgT9kE4KHqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Проект:** Классификация аудиозвонков на целевые и нецелевые."
      ],
      "metadata": {
        "id": "FaaxUmqWKHqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Цель проекта:** Разработать нейронную сеть, способную классифицировать аудиозвонки на целевые и нецелевые на основе предоставленной базы данных и csv-таблицы с описаниями и метками классов."
      ],
      "metadata": {
        "id": "GQSHmPOcKHq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Введение:**\n",
        "\n",
        "Входной набор данных представляет из себя два набора файлов:\n",
        "\n",
        "> a)\t[Первый набор файлов](https://drive.google.com/drive/folders/1cQWMpQkscZJbbOTxiJNy0o3nuaeIiB1P?usp=sharing) - это выгрузки в формате `CSV` с информацией по звонкам, а так же с проставленным статусом `“целевой/нецелевой”` в отдельном столбце (обратите внимание, что по проекту `“Павелецкая сити”` две выгрузки - эти наборы данных отличаются и относятся к разным наборам клиентов внутри одного и того же проекта).\n",
        "\n",
        "> b)\t[Второй набор файлов](https://drive.google.com/drive/folders/1K3jGCH60uzFcsI3aj89VIXOOFEXvZxD6?usp=sharing) - аудиозаписи звонков. Они хранятся в корневом каталоге в одноимённых папках. К примеру, в папке `“Записи звонков_павелецкая сити”` лежат записи звонков по проекту `“Павелецкая Сити”`."
      ],
      "metadata": {
        "id": "-UhJ6TikKHq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Требования:**\n",
        "\n",
        "1.   Нейронная сеть должна быть спроектирована и обучена для точной классификации аудиозвонков на два класса: целевые и нецелевые (с точностью `90+%`).\n",
        "2.   Необходимо обеспечить интеграцию модели через `API`.\n",
        "3.   Модель должна быть оптимизирована для обработки большого объёма данных.\n",
        "4.   Код должен быть написан с соблюдением стандартов кодирования, и должна быть составлена подробная техническая документация.\n",
        "5.   Код должен включать в себя систему журналирования для фиксации ошибок.\n",
        "6.   Код должен принимать на вход регулярное выражение, по которому будет осуществляться проверка столбца `“теги”` в выгрузках `CSV` для определения статуса звонка `“целевой/нецелевой”`:\n",
        "\n",
        ">> a)\tпо проектам `“Примавера”` и `“Павелецкая сити”` наличие в столбце с тегами подстроки `“Целевой_М108“` будет равняться тому, что данный звонок целевой (пример регулярного выражения: `.*Целевой_М108.*`);\n",
        "\n",
        ">> b)\tпо проекту `“Хедлайнер”` - наличие в столбце с тегами подстроки `“первичный целевой“` будет равняться тому, что данный звонок целевой.\n",
        "\n",
        "7.   После реализации необходимо иметь возможность получения поддержки по предоставленному решению в течение `2 месяцев`."
      ],
      "metadata": {
        "id": "13vIGhs0KHq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Список рекомендуемых параметров для звуковой записи (данный список носит информационный характер и не является обязательным):\n",
        "\n",
        "*   Эмоция (базовые 11: радость; печаль; гнев; отвращение; удивление; страдание (горе); волнение (интерес); презрение; смущение; стыд; вина).\n",
        "*   Пол.\n",
        "*   Возраст.\n",
        "*   Семантический анализ диалога (по конкретным ключевым словам и/или по тематикам диалогов).\n",
        "*   Характеристики, присутствующие в `CSV`/`XLSX` таблицах."
      ],
      "metadata": {
        "id": "seG9MxfuKHq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Критерии классификации"
      ],
      "metadata": {
        "id": "pTohUadq_HUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Критерии `уникально-целевого` обращения:\n",
        "1. Длительность звонка должна быть не менее `75 секунд`;\n",
        "2. Телефонный номер абонента должен быть `уникальным`, т. е. его не должно быть в `CRM` заказчика. Либо, по нему не должно быть активности за последние `90 дней`. Исключение составляют `топовые площадки`, работающие по своим критериям (`ЦИАН`, `Яндекс.Недвижимость`, `Авито`, и т. д.);\n",
        "3. Клиент должен знать минимальную информацию об объекте (понимать, куда он звонит): название `ЖК`, расположение, ценовую политику;\n",
        "4. Номер абонента должен быть доступен в течение `15 дней` после совершённого звонка (при этом со стороны заказчика должно быть обеспечено `2 попытки` исходящего звонка в течение указанного срока);\n",
        "5. Клиент должен быть `«адекватным»`. Не общаться на повышенных тонах, не употреблять ненормативную лексику и т. д.;\n",
        "6. Клиент не должен быть повторным. Например, клиент `уже` купил квартиру и через `90 дней` решил купить машиноместо;\n",
        "7. Заявка. В заявке должен быть указан номер телефона, а абонент при контакте с менеджером должен соответствовать всем критериям `уникально-целевого` обращения, перечисленным выше;\n",
        "8. Озвученный общий бюджет покупки не должен быть `ниже 90%` от стоимости квартиры или коммерческого помещения, соответствующих площади/комнатности на момент обращения;\n",
        "9. В случае, если клиент является уникальным, интересуется покупкой недвижимости, не является представителем партнёров или исполнителей и изъявил желание посетить офис продаж. При этом не обязательна фиксация уровня знания клиента об объекте в диалоге. При этом источник не должен относиться к каналам `«лидогенерация»` или `«тематические площадки»`;\n",
        "10. Основной целью звонка клиента не должна являться покупка/аренда исключительно нежилого помещения, если это не являлось целью проводимой рекламной кампании.\n",
        "\n",
        "Критерии НЕ `уникально-целевого` (вторичного) обращения:\n",
        "1. Клиент позвонил повторно менее чем через `3 месяца` (`90 дней`) с момента последнего обращения;\n",
        "2. Клиент, либо члены его семьи, уже купил (купили) `квартиру`/`машиноместо`/`кладовое помещение`, и хочет (хотят) совершить ещё одну покупку. В данном случае клиент относится к показателю `LTV` (показатель прибыли, которую компания получает от одного клиента за всё время работы с ним)."
      ],
      "metadata": {
        "id": "F1Im0SOi_S8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Датафреймы](https://drive.google.com/drive/folders/111abiHt33Q-SV48pBPhEgDCZDI5KshnF?usp=sharing)"
      ],
      "metadata": {
        "id": "GeEu96leTaL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Headliner"
      ],
      "metadata": {
        "id": "KXdYsYQmr1Aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Headliner_df.pkl` Информация о звонках `Headliner`](https://drive.google.com/file/d/13mUHwvx79O4P-AucRdjBYkN5ha8LnCSp/view?usp=sharing)\n",
        "*   [`Headliner_new_df.pkl` Информация о новых звонках `Headliner`](https://drive.google.com/file/d/1-Q1BxLbot7svY5hiqOquHRFvSOcwtpKS/view?usp=sharing)"
      ],
      "metadata": {
        "id": "d5AY3J4YBxrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Headliner_calls_df.pkl` Файлы записей звонков `Headliner`](https://drive.google.com/file/d/13pmGEYacsEHjYsIsYgf6fg4MUHAw509y/view?usp=sharing)\n",
        "*   [`Headliner_new_calls_df.pkl` Файлы записей новых звонков `Headliner`](https://drive.google.com/file/d/1-Ke1q42th_NV0og0e01_-mvJ8HL8JzfS/view?usp=sharing)"
      ],
      "metadata": {
        "id": "to-Y1bSQr-4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Headliner_all_df.pkl` Информация о всех звонках `Headliner`](https://drive.google.com/file/d/1857LwaVtJ364yFMpXemILSuVu84YEPPw/view?usp=sharing)\n",
        "*   [`Headliner_work_df.pkl` Рабочий датафрейм с информацией о всех звонках `Headliner`](https://drive.google.com/file/d/1-HOWuSAngv9dXYiMlyRXX0kmVVAAT4sV/view?usp=sharing)\n",
        "*   [`Headliner_targets_df.pkl` Целевые звонки `Headliner`](https://drive.google.com/file/d/1-J1gcgb2mrNDx3R_3l12kq0htS8PTkSv/view?usp=sharing)\n",
        "*   [`Headliner_not_targets_df.pkl` Нецелевые звонки `Headliner`](https://drive.google.com/file/d/1dGf3UrVeQg0VfFhBL_lZfm-gaczPYBnL/view?usp=sharing)\n",
        "*   [`Headliner_moot_df.pkl` Спорные звонки `Headliner`](https://drive.google.com/file/d/1-7vtN8vJNWgWfY8JE8bqoRXkUpvRE_og/view?usp=sharing)"
      ],
      "metadata": {
        "id": "15htzuzHJkr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Primavera"
      ],
      "metadata": {
        "id": "4BipOv18sV2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Primavera_df.pkl` Информация о звонках `Primavera`](https://drive.google.com/file/d/1-3csPnjIJXviKJzvbpCfOm29nBgl8L4Q/view?usp=sharing)\n",
        "*   [`Primavera_new_df.pkl` Информация о новых звонках `Primavera`](https://drive.google.com/file/d/1-QmWkabU2_cyrXPeVaiHSt2e6sLuiCtp/view?usp=sharing)"
      ],
      "metadata": {
        "id": "b8tnpm8LB43M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Primavera_calls_df.pkl` Файлы записей звонков `Primavera`](https://drive.google.com/file/d/1-CLRfPyaGSc61OopNuFRlWTG-CBCaM1F/view?usp=sharing)\n",
        "*   [`Primavera_new_calls_df.pkl` Файлы записей новых звонков `Primavera`](https://drive.google.com/file/d/1-Lxa0KifMiByareL94rdEzEpvvMj4D1T/view?usp=sharing)"
      ],
      "metadata": {
        "id": "ODp0MWUysgH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Primavera_all_df.pkl` Информация о всех звонках `Primavera`](https://drive.google.com/file/d/1-2-RlxkKHj5e6RkvbrN7_vs1h5aVXJFk/view?usp=sharing)\n",
        "*   [`Primavera_work_df.pkl` Рабочий датафрейм с информацией о всех звонках `Primavera`](https://drive.google.com/file/d/1-INI9JsU9jsOkPDiGMKhftt18KXgF6-K/view?usp=sharing)\n",
        "*   [`Primavera_targets_df.pkl` Целевые звонки `Primavera`](https://drive.google.com/file/d/1-JVtM9fOr6XoM7MVxkoVsYfwdZ6GQ--i/view?usp=sharing)\n",
        "*   [`Primavera_not_targets_df.pkl` Нецелевые звонки `Primavera`](https://drive.google.com/file/d/1-KwG8M-0wEn-5C4ta-B8_xYGCXDOhpnH/view?usp=sharing)"
      ],
      "metadata": {
        "id": "7JWVpnvgKgXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paveletskaya_city"
      ],
      "metadata": {
        "id": "1PeeinuNtAEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Paveletskaya_city_df.pkl` Информация о звонках `Paveletskaya_city`](https://drive.google.com/file/d/1-99dLkSvU3wdwjkGJpwpYUXQjxx8dwEu/view?usp=sharing)\n",
        "*   [`Paveletskaya_df.pkl` Информация о звонках `Paveletskaya_city`](https://drive.google.com/file/d/1-D6LlCFXQBMHceujvnq9H8rlx2jAnzmT/view?usp=sharing)\n",
        "*   [`Paveletskaya_city_new_df.pkl` Информация о новых звонках `Paveletskaya_city`](https://drive.google.com/file/d/1-Rtw9a1no3mKatUjc_FNv_bgUBdNrs_d/view?usp=sharing)"
      ],
      "metadata": {
        "id": "6IsB_F4xCAdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Paveletskaya_city_calls_df.pkl` Файлы записей звонков `Paveletskaya_city`](https://drive.google.com/file/d/1-JevsfOpxzLNZmSs34qrswhGzhPwf69S/view?usp=sharing)\n",
        "*   [`Paveletskaya_city_new_calls_df.pkl` Файлы записей новых звонков `Paveletskaya_city`](https://drive.google.com/file/d/1-ODEeFLv15DN5bfLlwyrTx8D3yxydhP9/view?usp=sharing)"
      ],
      "metadata": {
        "id": "N2krmwIptKI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`Paveletskaya_city_all_df.pkl` Информация о всех звонках `Paveletskaya_city`](https://drive.google.com/file/d/1-Cy78DqRZ3sbIHkg25wzVWPL-lST5oQa/view?usp=sharing)\n",
        "*   [`Paveletskaya_city_work_df.pkl` Рабочий датафрейм с информацией о всех звонках `Paveletskaya_city`](https://drive.google.com/file/d/1-J1BoALFH4-HRdVXjnkyr-fExmtQpUc7/view?usp=sharing)\n",
        "*   [`Paveletskaya_city_targets_df.pkl` Целевые звонки `Paveletskaya_city`](https://drive.google.com/file/d/1-MrjnBHDj65CEjJxLfPnp-hq07V_wtZK/view?usp=sharing)\n",
        "*   [`Paveletskaya_city_not_targets_df.pkl` Нецелевые звонки `Paveletskaya_city`](https://drive.google.com/file/d/1-WCCyYaorHkBYoh5ugNsCkD7cb1PKH6D/view?usp=sharing)"
      ],
      "metadata": {
        "id": "XUeydaKCLkch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сводные датафреймы"
      ],
      "metadata": {
        "id": "pdrl0p3jhcuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [`total_df.pkl` Сводный датафрейм с информацией о всех звонках](https://drive.google.com/file/d/15ijhw62sp2JNH6pryqZtM5akQHUnsTzi/view?usp=sharing)\n",
        "*   [`total_work_df.pkl` Сводный рабочий датафрейм с информацией о всех звонках](https://drive.google.com/file/d/1-056tLrjP5yRQW8yRtwutvXs3zmPulW7/view?usp=sharing)"
      ],
      "metadata": {
        "id": "388pbSo-pynK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 неделя"
      ],
      "metadata": {
        "id": "rVDYF0C9YQcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r sample_data"
      ],
      "metadata": {
        "id": "9KuUYa49Vo8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем google-диск\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_drv_path = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOx_s0fIVwbK",
        "outputId": "188d1a02-17da-405a-f038-d33d3f6e7712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Библиотеки и переменные"
      ],
      "metadata": {
        "id": "shwe_q3BV8Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os            # для работы с операционной системой\n",
        "import pickle as pkl # для сохранения и загрузки переменных\n",
        "import pandas as pd  # для работы с таблицами\n",
        "import numpy  as np  # для работы с массивами\n",
        "import re            # для работы с регулярными выражениями\n",
        "import whisper       # для транскрибации\n",
        "\n",
        "# Параметры отображения датафреймов\n",
        "pd.options.display.max_rows     = 99\n",
        "pd.options.display.max_columns  = 99\n",
        "pd.options.display.max_colwidth = 999\n",
        "\n",
        "work_dir_path              = my_drv_path           + 'media108.ru/Новички/'                # путь к рабочей папке\n",
        "df_path                    = work_dir_path         + 'Датафреймы/'                         # путь к папке для датафреймов\n",
        "table_path                 = work_dir_path         + 'Таблицы/'                            # путь к папке для таблиц\n",
        "model_path                 = work_dir_path         + 'Модели/'                             # путь к папке для моделей нейронных сетей\n",
        "all_dataset_path           = work_dir_path         + 'Датасет/'                            # путь к папке всего датасета в целом\n",
        "dataset_path               = all_dataset_path      + 'Записи звонков/'                     # путь к записям звонков\n",
        "dataset_info_path          = dataset_path          + 'Информация о звонках/'               # путь к информации о звонках\n",
        "dataset_new_path           = all_dataset_path      + 'Новые записи звонков/'               # путь к новым записям звонков\n",
        "dataset_new_info_path      = dataset_new_path      + 'Информация о звонках/'               # путь к информации о новых звонках\n",
        "Headliner_path             = dataset_path          + 'Записи звонков_хедлайнер'            # путь к записям звонков проекта Headliner\n",
        "Headliner_info             = dataset_info_path     + 'Headliner.csv'                       # путь к информации о звонках проекта Headliner\n",
        "Headliner_new_path         = dataset_new_path      + 'Записи Headliner'                    # путь к записям новых звонков проекта Headliner\n",
        "Headliner_new_info         = dataset_new_info_path + 'Headliner.xlsx'                      # путь к информации о новых звонках проекта Headliner\n",
        "Primavera_path             = dataset_path          + 'Записи звонков_primavera'            # путь к записям звонков проекта Primavera\n",
        "Primavera_info             = dataset_info_path     + 'Primavera .csv'                      # путь к информации о звонках проекта Primavera\n",
        "Primavera_new_path         = dataset_new_path      + 'Записи Primavera'                    # путь к записям новых звонков проекта Primavera\n",
        "Primavera_new_info         = dataset_new_info_path + 'Примавера.xlsx'                      # путь к информации о новых звонках проекта Primavera\n",
        "Paveletskaya_city_path     = dataset_path          + 'Записи звонков_павелецкая сити'      # путь к записям звонков проекта Paveletskaya_city\n",
        "Paveletskaya_city_info     = dataset_info_path     + 'Павелецкая_ЖК_«Павелецкая_сити».csv' # путь к информации о звонках проекта Paveletskaya_city\n",
        "Paveletskaya_info          = dataset_info_path     + 'Павелецкая (pavcity.turbo.site).csv' # путь к информации о звонках проекта Paveletskaya_city\n",
        "Paveletskaya_city_new_path = dataset_new_path      + 'Записи Павелецкая сити'              # путь к записям новых звонков проекта Paveletskaya_city\n",
        "Paveletskaya_city_new_info = dataset_new_info_path + 'Павелецкая сити.xlsx'                # путь к информации о новых звонках проекта Paveletskaya_city"
      ],
      "metadata": {
        "id": "afuxbj6ibJz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Классификация текста с использованием моделей трансформеров](https://habr.com/ru/articles/655517/)"
      ],
      "metadata": {
        "id": "XXcNF0p1ALIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRbpD9jAGgz9",
        "outputId": "1f78ce36-e2aa-42f0-8bda-0c5d6ff2aa99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Данные"
      ],
      "metadata": {
        "id": "-TkTzxieElLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка датафрейма с данными о звонках\n",
        "with open(df_path + 'total_work_df.pkl', 'rb') as f:\n",
        "  total_work_df = pkl.load(f)"
      ],
      "metadata": {
        "id": "mwwZtO58PxM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['Текст whisper-транскрибации записи звонка', 'Класс']][df['Файл записи звонка'] != 'нет файла']"
      ],
      "metadata": {
        "id": "gFJkG5ru3Ib8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "tr_df, val_df     = train_test_split(df,    test_size=0.2,  random_state=42, stratify=df['Класс'])\n",
        "train_df, test_df = train_test_split(tr_df, test_size=0.25, random_state=42, stratify=tr_df['Класс'])\n",
        "train_df.shape[0], val_df.shape[0], test_df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncgk68sgT7uP",
        "outputId": "d4aaf4da-e21a-4d65-913a-d0d92f4e6cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4152, 1385, 1384)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from   torch.utils.data import TensorDataset, RandomSampler, DataLoader, SequentialSampler\n",
        "from   transformers     import BertTokenizer\n",
        "\n",
        "train_text       = train_df['Текст whisper-транскрибации записи звонка'].astype('str')\n",
        "train_labels     = train_df['Класс']\n",
        "val_text         = val_df  ['Текст whisper-транскрибации записи звонка'].astype('str')\n",
        "val_labels       = val_df  ['Класс']\n",
        "test_text        = test_df ['Текст whisper-транскрибации записи звонка'].astype('str')\n",
        "test_labels      = test_df ['Класс']\n",
        "\n",
        "tokenizer        = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-sentence')\n",
        "\n",
        "tokens_train     = tokenizer.batch_encode_plus(train_text.values,\n",
        "                                           max_length=512,\n",
        "                                           padding='max_length',\n",
        "                                           truncation=True)\n",
        "\n",
        "tokens_val       = tokenizer.batch_encode_plus(val_text.values,\n",
        "                                           max_length=512,\n",
        "                                           padding='max_length',\n",
        "                                           truncation=True)\n",
        "\n",
        "tokens_test      = tokenizer.batch_encode_plus(test_text.values,\n",
        "                                           max_length=512,\n",
        "                                           padding='max_length',\n",
        "                                           truncation=True)\n",
        "\n",
        "train_seq        = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask       = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y          = torch.tensor(train_labels.values)\n",
        "\n",
        "val_seq          = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask         = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y            = torch.tensor(val_labels.values)\n",
        "\n",
        "test_seq         = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask        = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y           = torch.tensor(test_labels.values)\n",
        "\n",
        "batch_size       = 8\n",
        "\n",
        "train_data       = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_sampler    = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "val_data         = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler      = SequentialSampler(val_data)\n",
        "val_dataloader   = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "c06376b64b0e4f29b942e291d2cc2297",
            "fff0f26390504d4fa2ea4bf4ceee0ad6",
            "e4e18efff7904b17bf73eb828d78dc6c",
            "93493b81b2964abaaae47f71a6a8a0ad",
            "f6395518667a4652bc305ddab2ab3ed9",
            "9f1960b43dfe46899fe30fbdcf264303",
            "aa1a4b81111a45eebc0664559859e629",
            "7bf2bec9161345ababc651e67295b9ca",
            "77fe0b269cef42a886eaa7389d2e4357",
            "5ec78541491a443d9c8f4ef3b409c122",
            "a0d5fd0ad4a1431ebc4c11a89cfea22c",
            "6c5daf3ea2594454933794bf4cc50ed9",
            "d02e375756aa4e6491f001c607ff679a",
            "51c64d24707b411c8cc153b409b8ec64",
            "de61a71d91eb44d1a663c17b8d1858c9",
            "4d235c26e867482d8bddde96858030c0",
            "76387a2cbb9541bc8258c3ca7a0adb59",
            "531d210a224a46698dcf3411a3fc6b5b",
            "9ce6474028644a4c9a723ca9c171aa23",
            "5a8729fb986e43589d463bdb005b16b9",
            "b887a525c724442db447e6188ebef954",
            "2b3ecc5bff6f48ef942809d7bc7c304a",
            "ce0d8921f5ae4582b526af44ad6cb7f0",
            "5c864cc2ad9e4cb19472dfda0813cca6",
            "f4e9cec2644645ada534438a4411c056",
            "1905141356c84bdab1c0030955dcef3a",
            "9a85cc4af0b04a31a596d726a6f82df5",
            "c7fc24c6dc164cc0b5cf1fbd393f4038",
            "1a8f01d58e4641c3a43749a478ef53fd",
            "0cd88bac36194d7d97341172051b047e",
            "5800dd7c92e34c698c553efefff2b942",
            "dc36069605b74d9f8220e8eb596ca232",
            "f1c1c94b020045f48598cc69ef4b717b",
            "f3bbebe0654744eab4ac1d5124ce5f86",
            "dfa0ae9872ab416fae57073761246541",
            "589ab1145e774820b52169282272430a",
            "44962d355ac74f15be9bc6da937c03b2",
            "d8d759a1e3404f85ac9ec4f48d11dd65",
            "4d577f1dce7a4a389cea39330f5bd0e3",
            "d69da4ba2e5b48b992d081975c7d5051",
            "546fd2c7ab9948349ae0dde703f5ab31",
            "9b2559596717438e8d819d2df0e5ab51",
            "95795e51214f497688bcc84985c7ffee",
            "4860b3202fcb4a81a57a24d4e0be0cb3"
          ]
        },
        "id": "_HwvbfuEEqxF",
        "outputId": "2819b012-dfdd-4c5e-f39e-e9f90b17ef89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c06376b64b0e4f29b942e291d2cc2297"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c5daf3ea2594454933794bf4cc50ed9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce0d8921f5ae4582b526af44ad6cb7f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3bbebe0654744eab4ac1d5124ce5f86"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = [len(str(i).split()) for i in train_text]\n",
        "pd.Series(seq_len).hist(bins = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "iClirpi3YTFh",
        "outputId": "6aa48546-f11f-4fa8-c9ea-9eab1acf0475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "WWe47cxVRTHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "bert = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased-sentence')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0966193352664a5e82bd545a538842ed",
            "a2eab0a1b39e48e1828a6b36d1534158",
            "23a9f580279247faa054d117c314abb0",
            "88b0c079f3c34263aedc240bdcbef1ed",
            "9225adb975324bf8ab4c93731b8bba7c",
            "e0aaa17b53184ca698437444eca07f7a",
            "84e3fb5e84184d42b8cf6fe62d68d0ae",
            "d4896a7e551440a69c414fee212e247b",
            "7d4068fec9904d1e8ad8e18a69713e0a",
            "437f41c83eac482b89523d5320c8927c",
            "dabb2cc469424c4bb6a193c097e198d2"
          ]
        },
        "id": "O4hRNhsmRXwY",
        "outputId": "4873e77d-09a6-4c39-9b6b-c4ec8e0db56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0966193352664a5e82bd545a538842ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in bert.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "JCUh9r66YtYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "  def __init__(self, bert):\n",
        "    super(BERT_Arch, self).__init__()\n",
        "    self.bert = bert\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc1 = nn.Linear(768,512)\n",
        "    self.fc2 = nn.Linear(512,2)\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, sent_id, mask):\n",
        "    _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
        "    x = self.fc1(cls_hs)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.softmax(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "zhUYqcvXY45-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "model  = BERT_Arch(bert)\n",
        "model  = model.to(device)"
      ],
      "metadata": {
        "id": "UjLIQ_UZZhpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from   sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "print(class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5VeYsX3aAmQ",
        "outputId": "372952c9-3bc9-4d8c-dd36-bd3a138dddbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7446198  1.52199413]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "WuFuw7yHabtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "3-lnD305iTR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def train():\n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  total_preds = []\n",
        "\n",
        "  for step, batch in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n",
        "    batch = [r.to(device) for r in batch]\n",
        "    sent_id,mask,labels = batch\n",
        "    model.zero_grad()\n",
        "    preds = model(sent_id, mask)\n",
        "    loss = cross_entropy(preds, labels)\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  total_preds = np.concatenate(total_preds, axis = 0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "ERenGkTaaVXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0,0\n",
        "  total_preds = []\n",
        "\n",
        "  for step, batch in tqdm(enumerate(val_dataloader), total = len(val_dataloader)):\n",
        "    batch = [t.to(device) for t in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      preds = model(sent_id, mask)\n",
        "      loss = cross_entropy(preds, labels)\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  avg_loss = total_loss / len(val_dataloader)\n",
        "  total_preds = np.concatenate(total_preds, axis = 0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "hbYZUxtzdj88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTIkgLH7cu1-",
        "outputId": "06c8b2f0-a8d0-428b-b23c-2d72ae0dada3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs          = 25\n",
        "best_valid_loss = float('inf')\n",
        "best_loss       = float('inf')\n",
        "\n",
        "train_losses    = []\n",
        "valid_losses    = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
        "\n",
        "  train_loss, _ = train()\n",
        "  valid_loss, _ = evaluate()\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/media108.ru/Модели/bert_saved_weights.pt')\n",
        "  if valid_loss == best_valid_loss:\n",
        "    if train_loss < best_loss:\n",
        "      best_loss = train_loss\n",
        "      torch.save(model.state_dict(), '/content/drive/MyDrive/media108.ru/Модели/bert_saved_weights.pt')\n",
        "\n",
        "  train_losses.append(train_loss)\n",
        "  valid_losses.append(valid_loss)\n",
        "  print(f'\\nTraining loss: {train_loss:.3f}')\n",
        "  print(f'Validation loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIgpdmdcc96f",
        "outputId": "56bbed37-93c3-4900-c979-56a3d501a3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch1 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:14<00:00,  3.86it/s]\n",
            "100%|██████████| 174/174 [00:43<00:00,  4.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.373\n",
            "Validation loss: 0.312\n",
            "\n",
            " Epoch2 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:20<00:00,  3.69it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.345\n",
            "Validation loss: 0.304\n",
            "\n",
            " Epoch3 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:22<00:00,  3.64it/s]\n",
            "100%|██████████| 174/174 [00:44<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.337\n",
            "Validation loss: 0.310\n",
            "\n",
            " Epoch4 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.325\n",
            "Validation loss: 0.298\n",
            "\n",
            " Epoch5 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:22<00:00,  3.65it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.331\n",
            "Validation loss: 0.311\n",
            "\n",
            " Epoch6 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.67it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.324\n",
            "Validation loss: 0.288\n",
            "\n",
            " Epoch7 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:22<00:00,  3.65it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.320\n",
            "Validation loss: 0.285\n",
            "\n",
            " Epoch8 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.67it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.316\n",
            "Validation loss: 0.299\n",
            "\n",
            " Epoch9 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.67it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.311\n",
            "Validation loss: 0.365\n",
            "\n",
            " Epoch10 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:22<00:00,  3.65it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.316\n",
            "Validation loss: 0.287\n",
            "\n",
            " Epoch11 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.67it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.307\n",
            "Validation loss: 0.279\n",
            "\n",
            " Epoch12 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:22<00:00,  3.65it/s]\n",
            "100%|██████████| 174/174 [00:44<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.304\n",
            "Validation loss: 0.284\n",
            "\n",
            " Epoch13 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.307\n",
            "Validation loss: 0.289\n",
            "\n",
            " Epoch14 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:44<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.301\n",
            "Validation loss: 0.301\n",
            "\n",
            " Epoch15 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.67it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.302\n",
            "Validation loss: 0.277\n",
            "\n",
            " Epoch16 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:22<00:00,  3.65it/s]\n",
            "100%|██████████| 174/174 [00:44<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.298\n",
            "Validation loss: 0.283\n",
            "\n",
            " Epoch17 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.303\n",
            "Validation loss: 0.289\n",
            "\n",
            " Epoch18 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.294\n",
            "Validation loss: 0.304\n",
            "\n",
            " Epoch19 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:44<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.291\n",
            "Validation loss: 0.305\n",
            "\n",
            " Epoch20 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.296\n",
            "Validation loss: 0.282\n",
            "\n",
            " Epoch21 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:22<00:00,  3.65it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.293\n",
            "Validation loss: 0.295\n",
            "\n",
            " Epoch22 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:22<00:00,  3.65it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.294\n",
            "Validation loss: 0.295\n",
            "\n",
            " Epoch23 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.298\n",
            "Validation loss: 0.294\n",
            "\n",
            " Epoch24 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.296\n",
            "Validation loss: 0.280\n",
            "\n",
            " Epoch25 / 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 519/519 [02:21<00:00,  3.66it/s]\n",
            "100%|██████████| 174/174 [00:45<00:00,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training loss: 0.293\n",
            "Validation loss: 0.296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тест"
      ],
      "metadata": {
        "id": "igEXYw-8JAOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/media108.ru/Модели/bert_saved_weights.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWRhqnzh0qgZ",
        "outputId": "5723738c-ad41-445c-a7b2-0f9d09a74352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "list_seq  = np.array_split(test_seq, 50)\n",
        "list_mask = np.array_split(test_mask, 50)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for num, elem in enumerate(list_seq):\n",
        "  with torch.no_grad():\n",
        "    preds = model(elem.to(device), list_mask[num].to(device))\n",
        "    predictions.append(preds.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "2FM5D3glE4YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_preds = [item[1] for sublist in predictions for item in sublist]\n",
        "flat_preds = (flat_preds - min(flat_preds)) / (max(flat_preds) - min(flat_preds))\n",
        "test_df['Предсказание класса'] = flat_preds"
      ],
      "metadata": {
        "id": "eiHuIXtN1Npr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Порог 0.95\n",
        "from sklearn.metrics import classification_report\n",
        "test_df['Предсказание класса'] = test_df['Предсказание класса'].apply(lambda x: 1 if x > 0.95 else 0)\n",
        "print(classification_report(test_df['Класс'], test_df['Предсказание класса']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THycGY8h1q-M",
        "outputId": "b75ae27a-91af-42f3-e636-c43f134fb580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.91       930\n",
            "           1       0.80      0.85      0.83       454\n",
            "\n",
            "    accuracy                           0.88      1384\n",
            "   macro avg       0.87      0.88      0.87      1384\n",
            "weighted avg       0.89      0.88      0.88      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Порог 0.93\n",
        "test_df['Предсказание класса'] = test_df['Предсказание класса'].apply(lambda x: 1 if x > 0.93 else 0)\n",
        "print(classification_report(test_df['Класс'], test_df['Предсказание класса']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQN-swf72plh",
        "outputId": "c7e0f3ea-e563-4fec-b625-dbba6b0e4aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.86      0.91       930\n",
            "           1       0.77      0.93      0.84       454\n",
            "\n",
            "    accuracy                           0.89      1384\n",
            "   macro avg       0.87      0.90      0.88      1384\n",
            "weighted avg       0.90      0.89      0.89      1384\n",
            "\n"
          ]
        }
      ]
    }
  ]
}